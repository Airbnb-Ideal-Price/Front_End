{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers, Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Embedding, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam, Adamax, Nadam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "# Other\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../CSV Files\"\n",
    "\n",
    "train = pd.read_csv(path+\"/train.csv\", index_col=\"id\")\n",
    "test = pd.read_csv(path+\"/test.csv\",  index_col=\"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrangle(X):\n",
    "    # make a copy\n",
    "    X = X.copy()\n",
    "    \n",
    "    # encode \"t\" and \"f\" as 1's and 0's\n",
    "    X['host_has_profile_pic'][X['host_has_profile_pic']=='t'] = 1\n",
    "    X['host_has_profile_pic'][X['host_has_profile_pic']=='f'] = 0\n",
    "    \n",
    "    X['host_identity_verified'][X['host_identity_verified']=='t'] = 1\n",
    "    X['host_identity_verified'][X['host_identity_verified']=='f'] = 0\n",
    "    \n",
    "    X['host_has_profile_pic'] = X['host_has_profile_pic'].astype(float)\n",
    "    X['host_identity_verified'] = X['host_identity_verified'].astype(float)\n",
    "    \n",
    "    X['instant_bookable'][X['instant_bookable']=='t'] = 1\n",
    "    X['instant_bookable'][X['instant_bookable']=='f'] = 0\n",
    "    \n",
    "    # Group some of the many property types together\n",
    "    X['property_type'][X['property_type'].isin(['Boat','Tent','Castle','Yurt', 'Hut', 'Treehouse',\n",
    "                                                'Chalet','Earth House','Tipi','Cave',\n",
    "                                                'Train','Parking Space','Island','Casa particular',\n",
    "                                                'Lighthouse', 'Vacation home', 'Serviced apartment'])] = 'Other'\n",
    "\n",
    "    # columns with unusable variance\n",
    "    unusable_variance = ['zipcode']\n",
    "\n",
    "    # columns with high percentage of missing values\n",
    "    high_nans = ['first_review','host_response_rate','last_review',\n",
    "                 'review_scores_rating','thumbnail_url']\n",
    "\n",
    "    # categorical variables with high cardinality\n",
    "    # 'neighborhood' has 620 and 'thumbnail_url' has many thousands\n",
    "    high_card = ['neighbourhood','thumbnail_url','name','amenities',\n",
    "                 'description', 'host_since']\n",
    "\n",
    "    # Get the price and drop the log of price\n",
    "    X['price'] = np.exp(X['log_price'])\n",
    "    X = X.drop(['log_price'] + unusable_variance + high_nans + high_card, axis=1)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test):\n",
    "    X_train_enc, X_test_enc = list(), list()\n",
    "    # label encode each column\n",
    "    for i in range(X_train.shape[1]):\n",
    "        le = LabelEncoder()\n",
    "        # encode\n",
    "        train_enc = le.fit_transform(X_train.iloc[:, i].values)\n",
    "        test_enc = le.fit_transform(X_test.iloc[:, i].values)\n",
    "        # store\n",
    "        X_train_enc.append(train_enc)\n",
    "        X_test_enc.append(test_enc)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_inputs(X_train, X_test):\n",
    "    ss = StandardScaler()\n",
    "    ss.fit_transform(X_train, X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation_emb():\n",
    "    lr = .001\n",
    "    opt = Adam(lr)\n",
    "#     input_shape = 16\n",
    "#     prob = .50\n",
    "    l2 = 0.02\n",
    "\n",
    "    il_nodes = 10\n",
    "#     hl_nodes_1 = 64*8\n",
    "#     hl_nodes_2 = 64*8\n",
    "#     hl_nodes_3 = 64*8\n",
    "#     hl_nodes_4 = 64*8\n",
    "    ol_nodes = 1\n",
    "    \n",
    "    dense = Dense(il_nodes,\n",
    "                  activation='relu', \n",
    "                  kernel_regularizer=regularizers.l2(l2))(emb)\n",
    "    \n",
    "    output = Dense(ol_nodes,\n",
    "                   activation='linear')(dense)\n",
    "    \n",
    "    model = Model(inputs=in_layers,\n",
    "                  outputs=output)\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creation():\n",
    "    lr = .001\n",
    "    opt = Adam(lr)\n",
    "    input_shape = 16\n",
    "    prob = .50\n",
    "    l2 = 0.02\n",
    "\n",
    "    il_nodes = 64*8\n",
    "    hl_nodes_1 = 64*8\n",
    "    hl_nodes_2 = 64*8\n",
    "    hl_nodes_3 = 64*8\n",
    "    hl_nodes_4 = 64*8\n",
    "    ol_nodes = 1\n",
    "    \n",
    "    model = Sequential([\n",
    "    Dense(il_nodes, \n",
    "          activation='relu', \n",
    "          input_dim=input_shape,\n",
    "          kernel_regularizer=regularizers.l2(l2)),\n",
    "    \n",
    "    Dropout(prob),\n",
    "        \n",
    "    Dense(hl_nodes_1, \n",
    "          activation='relu',\n",
    "          kernel_regularizer=regularizers.l2(l2)),\n",
    "        \n",
    "    Dropout(prob),\n",
    "        \n",
    "    Dense(hl_nodes_2, \n",
    "          activation='relu',\n",
    "          kernel_regularizer=regularizers.l2(l2)),\n",
    "        \n",
    "    Dropout(prob),\n",
    "    \n",
    "    Dense(hl_nodes_3, \n",
    "          activation='relu',\n",
    "          kernel_regularizer=regularizers.l2(l2)),\n",
    "        \n",
    "    Dropout(prob),\n",
    "        \n",
    "    Dense(hl_nodes_4, \n",
    "          activation='relu',\n",
    "          kernel_regularizer=regularizers.l2(l2)),\n",
    "        \n",
    "    Dropout(prob),\n",
    "        \n",
    "    Dense(ol_nodes, \n",
    "          activation='linear')\n",
    "])\n",
    "    \n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics=['mean_absolute_error'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = wrangle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = 'price'\n",
    "X = train.drop(target, axis=1)\n",
    "y = train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=.20,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = mean_absolute_error(y_train, [y_train.mean()] * len(y_train))\n",
    "print('Baseline MAE:', round(baseline,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test = prepare_inputs(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = scale_inputs(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = [list(X_train[i]) for i in range(len(X_train))]\n",
    "# X_train = np.asarray(X_train).T\n",
    "\n",
    "# X_test = [list(X_test[i]) for i in range(len(X_test))]\n",
    "# X_test = np.asarray(X_test).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "in_layers, em_layers = list(), list()\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    n_labels = len(np.unique(X_train[i]))\n",
    "    in_layer = Input(shape=(1,))\n",
    "    em_layer = Embedding(n_labels, 10)(in_layer)\n",
    "    in_layers.append(in_layer)\n",
    "    em_layers.append(em_layer)\n",
    "    \n",
    "emb = concatenate(em_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_train.shape)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasRegressor(model_creation_emb, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "logdir = os.path.join(\"logs\", \"EarlyStopping\")\n",
    "\n",
    "board_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "# Not in use.\n",
    "stop = EarlyStopping(monitor=\"val_mean_absolute_error\",\n",
    "                     min_delta=1,\n",
    "                     patience=3)\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"weights_best.h5\", \n",
    "                             save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X_train, y_train,\n",
    "                   epochs=1, batch_size=32,\n",
    "                   validation_data=(X_test, y_test),\n",
    "                   callbacks=[board_callback, stop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(result.history)\n",
    "df['epoch'] = [i for i in range(df.shape[0])]\n",
    "\n",
    "plt.plot(df['epoch'], df['val_mean_absolute_error'], label=\"VMAE\")\n",
    "plt.plot(df['epoch'], df['mean_absolute_error'], label=\"MAE\")\n",
    "# plt.xticks(df['epoch'])\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.model.save('keras_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size': [32,64,512],\n",
    "    'epochs': [32,64,512],\n",
    "    'opt': [],\n",
    "    'lr': []\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(model,\n",
    "                    params,\n",
    "                    cv=2,\n",
    "                    n_jobs=-1,\n",
    "                    verbose=1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "print(f\"Mean test score: {grid_result.cv_results_['mean_test_score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
